from FlagEmbedding import FlagReranker
import numpy as np
from llama_index.core import Settings

def evaluate(reranked, reranked_doc_ids, ground_truth_doc_id):
    hit = ground_truth_doc_id in reranked_doc_ids
    recall = 1 if hit else 0

    try:
        rank = reranked_doc_ids.index(ground_truth_doc_id) + 1
        mrr = 1.0 / rank
    except ValueError:
        mrr = 0.0

    # ì •ë‹µì´ ëª‡ ë²ˆì§¸ì— ìˆëŠ”ê°€ì— ë”°ë¼ ì ìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ ë¶€ì—¬
    dcg = sum([
        1 / np.log2(i + 2) if doc_id == ground_truth_doc_id else 0
        for i, doc_id in enumerate(reranked_doc_ids)
    ])
    idcg = 1.0  # ì´ìƒì ì¸ DCG
    ndcg = dcg / idcg

    return recall, mrr, ndcg



def evaluate_single_query_rerank(reranker, query, ground_truth_doc_id, qdrant_client, embed_model, collection_name, k=5):
    # 1. ì¿¼ë¦¬ ì„ë² ë”©
    query_vector = embed_model.get_text_embedding(query)

    # 2. Qdrantì—ì„œ Top-K ê²€ìƒ‰
    results = qdrant_client.search(
        collection_name=collection_name,
        query_vector=query_vector,
        limit=k,
        with_payload=True
    )

    if not results:
        return 0, 0.0, 0.0  # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ

    # 3. query-document pairs ìƒì„±
    chunks = [pt.payload["text"] for pt in results]
    doc_ids = [pt.id.split("~")[0] for pt in results]
    pairs = [[query, text] for text in chunks]

    # 4. reranker ì ìˆ˜ ê³„ì‚°
    scores = reranker.compute_score(pairs, normalize=True)

    # 5. ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
    reranked = sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)
    reranked_doc_ids = [doc_id for doc_id, _ in reranked]

    return (reranked, reranked_doc_ids)

import qdrant_client
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

def hybrid_reranking(query, qdrant_client, collection_name, k=5):
    def arctan_normalize(score):
        return (2 / np.pi) * np.arctan(score)
    
    def search_and_rerank_hybrid(query, qdrant_client, collection_name, dense_model, reranker,
                              k=100, weights=None, decay=0.01):
        """
        3ê°€ì§€ ìŠ¤ì½”ì–´ ë¥¼ ëª¨ë‘ ê²°í•©í•˜ì—¬ rerankí•©ë‹ˆë‹¤. # + ë‚ ì§œ ì ìˆ˜ëŠ” ì œì™¸
        weights: {"dense": 0.4, "sparse": 0.4, "bm25": 0.1, "recency": 0.1}
        """
        if weights is None:
            weights = {"dense": 0.4, "sparse": 0.4, "bm25": 0.2, } # "recency": 0.1

        # Step 1. ì¿¼ë¦¬ ì„ë² ë”©
        dense_vector = dense_model.get_text_embedding(query)

        # Step 2. Qdrantì—ì„œ dense + sparse ê²€ìƒ‰
        results = qdrant_client.search(
            collection_name=collection_name,
            query_vector=dense_vector,
            limit=k,
            with_payload=True
        )

        if not results:
            return []

        # Step 3. ê°œë³„ ì ìˆ˜ ë¶„ë¦¬
        doc_ids = [pt.id.split("~")[0] for pt in results]
        texts = [pt.payload["text"] for pt in results]
        # dates = [pt.payload.get("published_date", "1900-01-01") for pt in results]
        
        query_doc_pairs = [[query, text] for text in texts]

        dense_scores = [pt.score for pt in results]  # Qdrant cosine similarity
        sparse_scores = reranker.compute_score(query_doc_pairs, normalize=True)   
        bm25_scores = [pt.payload.get("bm25_score", 0) for pt in results]

        # bm25 ì ìˆ˜ ì •ê·œí™”
        bm25_scores = arctan_normalize(bm25_scores)
        
        # recency_scores = [get_recency_score(d, decay=decay) for d in dates]
        final_scores = [
            weights["dense"] * d + weights["sparse"] * s + weights["bm25"] * b
            for d, s, b in zip(dense_scores, sparse_scores, bm25_scores )
        ]
        
        reranked = sorted(zip(doc_ids, texts, final_scores), key=lambda x: x[2], reverse=True)

        return reranked  # [(doc_id, text, final_score), ...]



    sparse_reranker = FlagReranker("dragonkue/bge-reranker-v2-m3-ko", use_fp16=True)

    

    # vector search ê²°ê³¼ ì¤‘ ìƒìœ„ 100ê°œ ë¬¸ì„œì— ëŒ€í•´ì„œë§Œ ì²˜ë¦¬ -> hybrid scoring ì ìš©
    results = search_and_rerank_hybrid(
        query=query,
        qdrant_client=qdrant_client,
        collection_name=collection_name,
        dense_model=Settings.embed_model,
        reranker=sparse_reranker,
        k=100,
        weights={"dense": 0.3, "sparse": 0.5, "bm25": 0.2 }, # , "recency": 0.1
        decay=0.01
    )

    for i, (doc_id, text, score) in enumerate(results[:10], 1):
        print(f"ğŸ”¹ Rank {i} | Score: {score:.4f}")
        print(f"{text}...\n")

    return results